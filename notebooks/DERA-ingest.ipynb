{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abf0869-f139-411a-9b34-51945c12cade",
   "metadata": {},
   "source": [
    "# Ingest SEC DERA data into Trino pipeline\n",
    "\n",
    "Copyright (C) 2021 OS-Climate\n",
    "\n",
    "This sample shows:\n",
    "* How to create schemas and tables via the Trino / SQLAlchemy on an underlying Iceberg data volume\n",
    "* Apache Iceberg ACID transaction and time travel capabilities used for data set versioning\n",
    "\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "Contributed by Michael Tiemann (Github: MichaelTiemannOSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dd1fc-8b99-4829-be30-a525634f26d9",
   "metadata": {},
   "source": [
    "%%capture pipoutput\n",
    "%pip install boto3 python-dotenv\n",
    "%pip install --upgrade sqlalchemy==1.3 sqlalchemy-trino\n",
    "%pip install pandas pyarrow fastparquet\n",
    "%pip install anytree\n",
    "%pip install osc-ingest-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789567ff-268c-45e8-8f6f-e768ba62f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "from osc_ingest_trino import *\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import trino\n",
    "from sqlalchemy.engine import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7692120-2f4f-48be-9847-0f78a3359bc1",
   "metadata": {},
   "source": [
    "Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba14b4-0746-4ce6-9c0f-ff680221bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fa84b-d4c0-4dd6-99da-2cab1641ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_LANDING_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_LANDING_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_LANDING_SECRET_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb78b98-863c-4626-adab-8c5d9dd6b094",
   "metadata": {},
   "source": [
    "Create a simple data frame for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d2fb6-75b5-488b-b4ac-8c2186517c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "buffer = io.BytesIO()\n",
    "sub_file = s3_resource.Object(os.environ['S3_LANDING_BUCKET'],'SEC-DERA/2020q4/sub.txt')\n",
    "sub_file.download_fileobj(buffer)\n",
    "buffer.seek(0)\n",
    "df = pd.read_csv(buffer, header=0, sep='\\t', nrows=20, engine='c')\n",
    "new_df = df.iloc[10:20]\n",
    "df = df.iloc[0:10]\n",
    "\n",
    "# Add a unique identifier to the data set\n",
    "uid = str(uuid.uuid4())\n",
    "df['uuid'] = uid\n",
    "# Print the output\n",
    "df = df.convert_dtypes()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94102c-8c8e-450a-b95e-ea5a368fe09f",
   "metadata": {},
   "source": [
    "Create custom meta data and declare variable for schema and table for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb738ec4-a29c-411a-aaa4-bed1afd9955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc3dea-79c1-4ed6-a21a-b89032981fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_meta_content = {\n",
    "    'dataset_key': 'SEC-DERA',\n",
    "    'title': 'SEC DERA Disclosures',\n",
    "    'description': \n",
    "    '''The DERA Financial Statement Data Sets provide numeric information from the face financials of all financial statements.\n",
    "    \n",
    "    This data is extracted from exhibits to corporate financial reports filed with the Commission using eXtensible Business Reporting Language (XBRL).  As compared to the more extensive Financial Statement and Notes Data Sets, which provide the numeric and narrative disclosures from all financial statements and their notes, the Financial Statement Data Sets are more compact.''',\n",
    "    'version': '2020q4',\n",
    "    'release_date': '20201231',\n",
    "    'fields': [\n",
    "    {\n",
    "        'adsh':'Accession Number. The 20-character string formed from the 18-digit number assigned by the SEC to each EDGAR submission.',\n",
    "        'cik':'Central Index Key (CIK). Ten digit number assigned by the SEC to each registrant that submits filings.',\n",
    "        'name':'Name of registrant. This corresponds to the name of the legal entity as recorded in EDGAR as of the filing date.',\n",
    "        'sic':'Standard Industrial Classification (SIC). Four digit code assigned by the SEC as of the filing date, indicating the registrant’s type of business.',\n",
    "        'countryba':'The ISO 3166-1 country of the registrant’s business address.',\n",
    "        'stprba':'The state or province of the registrant’s business address, if field countryba is US or CA.',\n",
    "        'cityba':'The city of the registrant’s business address.',\n",
    "        'zipba':'The zip code of the registrant’s business address.',\n",
    "        'bas1':'The first line of the street of the registrant’s business address.',\n",
    "        'bas2':'The second line of the street of the registrant’s business address.',\n",
    "        'baph':'The phone number of the registrant’s business address.',\n",
    "        'countryma':'The ISO 3166-1 country of the registrant’s mailing address.',\n",
    "        'stprma':'The state or province of the registrant’s mailing address, if field countryma is US or CA.',\n",
    "        'cityma':'The city of the registrant’s mailing address.',\n",
    "        'zipma':'The zip code of the registrant’s mailing address.',\n",
    "        'mas1':'The first line of the street of the registrant’s mailing address.',\n",
    "        'mas2':'The second line of the street of the registrant’s mailing address.',\n",
    "        'countryinc':'The country of incorporation for the registrant.',\n",
    "        'stprinc':'The state or province of incorporation for the registrant, if countryinc is US or CA.',\n",
    "        'ein':'Employee Identification Number, 9 digit identification number assigned by the Internal Revenue Service to business entities operating in the United States.',\n",
    "        'former':'Most recent former name of the registrant, if any.',\n",
    "        'changed':'Date of change from the former name, if any.',\n",
    "        'afs':'Filer status with the SEC at the time of submission:\\n\\\n",
    "1-LAF=Large Accelerated,\\n\\\n",
    "2-ACC=Accelerated,\\n\\\n",
    "3-SRA=Smaller Reporting Accelerated,\\n\\\n",
    "4-NON=Non-Accelerated,\\n\\\n",
    "5-SML=Smaller Reporting Filer,\\n\\\n",
    "NULL=not assigned.',\n",
    "        'wksi':'Well Known Seasoned Issuer (WKSI). An issuer that meets specific SEC requirements at some point during a 60-day period preceding the date the issuer satisfies its obligation to update its shelf registration statement.',\n",
    "        'fye':'Fiscal Year End Date, rounded to nearest month-end.',\n",
    "        'form':'The submission type of the registrant’s filing.',\n",
    "        'period':'Balance Sheet Date, rounded to nearest month-end.',\n",
    "        'fy':'Fiscal Year Focus (as defined in EFM Ch. 6).',\n",
    "        'fp':'Fiscal Period Focus (as defined in EFM Ch. 6) within Fiscal Year. The 10-Q for the 1st, 2nd and 3rd quarters would have a fiscal period focus of Q1, Q2 (or H1), and Q3 (or M9) respectively, and a 10-K would have a fiscal period focus of FY.',\n",
    "        'filed':'The date of the registrant’s filing with the Commission.',\n",
    "        'accepted':'The acceptance date and time of the registrant’s filing with the Commission. Filings accepted after 5:30pm EST are considered filed on the following business day.',\n",
    "        'prevrpt':'Previous Report –TRUE indicates that the submission information was subsequently amended.',\n",
    "        'detail':'TRUE indicates that the XBRL submission contains quantitative disclosures within the footnotes and schedules at the required detail level (e.g., each amount).',\n",
    "        'instance':'The name of the submitted XBRL Instance Document (EX-101.INS) type data file. The name often begins with the company ticker symbol.',\n",
    "        'nciks':'Number of Central Index Keys (CIK) of registrants (i.e., business units) included in the consolidating entity’s submitted filing.',\n",
    "        'aciks':'Additional CIKs of co-registrants included in  a consolidating entity’s EDGAR submission, separated by spaces. If there are no other co-registrants (i.e., nciks=1), the value of aciks is NULL.  For a very small number of filers, the list of co-registrants is too long to fit in the field.  Where this is the case, PARTIAL will appear at the end of the list indicating that not all co-registrants’ CIKs are included in the field; users should refer to the complete submission file for all CIK information.'\n",
    "    }]\n",
    "}\n",
    "schemaname = 'sec_dera'\n",
    "tablename = 'sub'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c9a40-2fdb-40c0-9dd5-7e7bf53db3da",
   "metadata": {},
   "source": [
    "Convert custom metadata content in json format into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5ef1b-05d4-4319-9b6e-073816e2dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_fields = pd.json_normalize(custom_meta_content, record_path =['fields'], meta=['dataset_key']).convert_dtypes()\n",
    "df_meta_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89670f-677f-4a2c-a258-259c671ea99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_fields.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf1950-cd9c-4b61-b4d2-12a8d8fe4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_table = pd.json_normalize(custom_meta_content, max_level=0)\n",
    "df_meta_table.drop('fields', inplace=True, axis=1)\n",
    "df_meta_table['schema'] = schemaname\n",
    "df_meta_table = df_meta_table.convert_dtypes()\n",
    "df_meta_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da3217-69e2-45cf-bc89-07898eee4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_table.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efe080-b4eb-4713-8fd0-7f1d2e1fd966",
   "metadata": {},
   "source": [
    "Open a Trino connection using JWT for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b5e63-8d67-4314-844c-ae42266070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD']),\n",
    "    'http_scheme': 'https'\n",
    "}\n",
    "engine = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(engine))\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c59fba-9590-4e31-90c0-da8fa1d0316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute('show schemas in osc_datacommons_iceberg_dev').fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96687d-74a7-46d8-9944-b63fddf11bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogname = 'osc_datacommons_iceberg_dev'\n",
    "\n",
    "# Show available schemas to ensure trino connection is set correctly\n",
    "schema_read = engine.execute(f'show schemas in {catalogname}')\n",
    "for row in schema_read.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e2635-ac17-4dda-bc41-a5a18c61c44d",
   "metadata": {},
   "source": [
    "Create ingestion schema based on source data name and remove old tables if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa21228-ec3d-4506-820a-bb071b56fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_check = engine.execute(f'create schema if not exists {catalogname}.{schemaname}')\n",
    "for row in schema_check.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfcb2e-e07b-4b44-8868-1d1fde967bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute('show tables in osc_datacommons_iceberg_dev.sec_dera').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e809a5-85eb-4879-86ed-1b1c01e4104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_check = engine.execute(f'drop table if exists {catalogname}.{schemaname}.{tablename}')\n",
    "for row in table_check.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c7d8e-45f9-48e7-a0db-66b103d5b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = create_table_schema_pairs(df)\n",
    "tabledef = \"\"\"\n",
    "create table if not exists {cname}.{sname}.{tname} (\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    partitioning = ARRAY['uuid']\n",
    ")\n",
    "\"\"\".format(cname=catalogname, schema=schema, sname=schemaname, tname=tablename)\n",
    "print(tabledef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7ff81-b20b-436c-bdc1-9be72b536076",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_create = engine.execute(tabledef)\n",
    "for row in table_create.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6849aa-9841-46e1-84ee-a5448d29a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append data frame to new Trino table \n",
    "# this statement should work but receives a TrinoUserError: \"This connector does not support creating tables\"\n",
    "# df.to_sql('gppd', con=engine, schema='wri_test', if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5217f55-c15b-4eed-ae0d-0c6a0c51a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_values = df.values.tolist()\n",
    "list_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea871be-8ae0-402a-8f8c-241b6700cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_appropriately(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace(\"'\", \"′\")\n",
    "        return f\"'{x}'\"\n",
    "    if isinstance(x, (int,float)):\n",
    "        return str(x)\n",
    "    return 'NULL'\n",
    "\n",
    "list_length = len(list_values)\n",
    "for i in range(list_length):\n",
    "    joined_values = '(' + ','.join([quote_appropriately(x) for x in list_values[i]]) + ')'\n",
    "    insert_statement = \"\"\"INSERT INTO {cname}.{sname}.{tname} \n",
    "    VALUES \"\"\".format(cname=catalogname, sname=schemaname, tname=tablename) + joined_values\n",
    "    print(insert_statement)\n",
    "    run_statement = engine.execute(insert_statement)\n",
    "    for row in run_statement.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359dac5-4b68-4873-98f0-46e231fb5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_query = ('SELECT * FROM {cname}.{sname}.{tname} limit 10').format(cname=catalogname,sname=schemaname,tname=tablename)\n",
    "print(dataset_query)\n",
    "dataset = engine.execute(dataset_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f5c13-c5df-4f0c-b2e1-866782bb6263",
   "metadata": {},
   "source": [
    "Query Iceberg snapshots for WRI GPPD data set. Snapshots allow having an immutable set of the data at a given time. They are automatically created on every append or removal of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9a5da-9cc2-414c-add9-0e8d32f913e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_query = ('SELECT committed_at, snapshot_id, parent_id FROM {cname}.{sname}.\\\"{tname}$snapshots\\\"').format(cname=catalogname,sname=schemaname,tname=tablename)\n",
    "print(snapshot_query)\n",
    "dataset = engine.execute(snapshot_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87b7dd-d925-4eac-a5d4-edb831d3756f",
   "metadata": {},
   "source": [
    "Create metadata table for schema / dataset level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2dc67-842b-4b9e-98ed-64e1261b2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variable names for metadata structure in Trino\n",
    "meta_schema_name = 'metastore_iceberg'\n",
    "meta_table_name_dataset = 'meta_tables_iceberg'\n",
    "meta_table_name_fields = 'meta_fields_iceberg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b792868-2a2b-474a-bbb6-b5c7f1f576d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_check = engine.execute(f'create schema if not exists {catalogname}.' + meta_schema_name)\n",
    "for row in schema_check.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8863ecf-4352-4e5f-8b8d-69b577c9d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_check = engine.execute(f'drop table if exists {catalogname}.' + meta_schema_name + '.' + meta_table_name_dataset)\n",
    "for row in table_check.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72008b37-fada-47e2-9c92-7099a4a950e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_meta_table = create_table_schema_pairs(df_meta_table)\n",
    "tabledef = \"\"\"\n",
    "create table if not exists {cname}.{sname}.{tname} (\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    partitioning = ARRAY['dataset_key']\n",
    ")\n",
    "\"\"\".format(cname=catalogname, schema=schema_meta_table, sname=meta_schema_name, tname=meta_table_name_dataset)\n",
    "print(tabledef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6a5ad-f8bb-44d0-8e87-34576d08c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_table_create = engine.execute(tabledef)\n",
    "for row in meta_table_create.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59ca47-dae8-4883-b616-531f85be9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_values_meta_table = df_meta_table.values.tolist()\n",
    "list_values_meta_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ef261-d51c-40bf-a1a1-bad4a0cd2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_values = '(\\'' + list_values_meta_table[0][0] + '\\', \\'' + list_values_meta_table[0][1] + '\\', \\'' + list_values_meta_table[0][2] + '\\', \\'' + list_values_meta_table[0][3] + '\\', \\'' + list_values_meta_table[0][4] + '\\', \\'' + list_values_meta_table[0][5] + '\\')'\n",
    "insert_statement = \"\"\"INSERT INTO osc_datacommons_iceberg_dev.{sname}.{tname} \n",
    "VALUES \"\"\".format(sname=meta_schema_name,tname=meta_table_name_dataset) + joined_values\n",
    "print(insert_statement)\n",
    "run_statement = engine.execute(insert_statement)\n",
    "for row in run_statement.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0c4ea-89c6-4ab7-895c-89217f8c962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_query_table = ('SELECT * FROM osc_datacommons_iceberg_dev.{sname}.{tname} limit 10').format(sname=meta_schema_name,tname=meta_table_name_dataset)\n",
    "print(meta_query_table)\n",
    "meta_table_query = engine.execute(meta_query_table)\n",
    "for row in meta_table_query.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac0007-d564-46e8-a111-a568b05355de",
   "metadata": {},
   "source": [
    "Create metadata table for fields information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1964ef-40f5-4285-b65d-c02ba2aa053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_check = engine.execute('drop table if exists osc_datacommons_iceberg_dev.' + meta_schema_name + '.' + meta_table_name_fields)\n",
    "for row in table_check.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0d1d2-1125-4286-b92c-b463f430e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_meta_fields = create_table_schema_pairs(df_meta_fields)\n",
    "tabledef = \"\"\"\n",
    "create table if not exists osc_datacommons_iceberg_dev.{sname}.{tname} (\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    partitioning = ARRAY['dataset_key']\n",
    ")\n",
    "\"\"\".format(schema=schema_meta_fields, sname=meta_schema_name, tname=meta_table_name_fields)\n",
    "print(tabledef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220516ae-6987-483b-b7e2-4b8ebaed083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fields_create = engine.execute(tabledef)\n",
    "for row in meta_fields_create.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683526c-3dea-404c-81bb-ae8450c11d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_values_meta_fields = df_meta_fields.values.tolist()\n",
    "list_values_meta_fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ce467-1528-4428-8695-fd2705a30b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fields_length = len(list_values_meta_fields)\n",
    "for i in range(list_fields_length):\n",
    "    joined_values = '(' + ','.join([quote_appropriately(x) for x in list_values_meta_fields[i]]) + ')'\n",
    "    insert_statement = \"\"\"INSERT INTO osc_datacommons_iceberg_dev.{sname}.{tname} \n",
    "    VALUES \"\"\".format(sname=meta_schema_name, tname=meta_table_name_fields) + joined_values\n",
    "    print(insert_statement)\n",
    "    run_statement = engine.execute(insert_statement)\n",
    "    for row in run_statement.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bcf2a-834f-4caf-8e35-d05b2ca32001",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_query_fields = ('SELECT * FROM osc_datacommons_iceberg_dev.{sname}.{tname} limit 10').format(sname=meta_schema_name, tname=meta_table_name_fields)\n",
    "print(meta_query_fields)\n",
    "meta_fields_query = engine.execute(meta_query_fields)\n",
    "for row in meta_fields_query.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c6984-a7a8-4c23-8a71-4003cf768e11",
   "metadata": {},
   "source": [
    "Update the source data to create a new data set for ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a3f92-4176-47fe-a314-333c76de18a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialise new data for powerplants and capacity\n",
    "\n",
    "# Set above, because it's a pain to wait to do it here\n",
    "# new_df = pd.read_csv(buffer, header=None, sep='\\t', nrows=10, engine='c')\n",
    "# new_df.columns = df.columns\n",
    "# Add a unique identifier to the data set\n",
    "uid = str(uuid.uuid4())\n",
    "new_df['uuid'] = uid\n",
    "# Print the output\n",
    "new_df = new_df.convert_dtypes()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e285c-3210-409a-a538-14e51f32a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_values = new_df.values.tolist()\n",
    "new_list_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b0137-23f7-41f8-9de4-ad22e25eb1b6",
   "metadata": {},
   "source": [
    "Ingest new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9ed92-0316-476b-bd29-d3dc6df02b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length = len(new_list_values)\n",
    "for i in range(list_length):\n",
    "    joined_values = '(' + ','.join([quote_appropriately(x) for x in new_list_values[i]]) + ')'\n",
    "    insert_statement = \"\"\"INSERT INTO osc_datacommons_iceberg_dev.{sname}.{tname} \n",
    "    VALUES \"\"\".format(sname=schemaname, tname=tablename) + joined_values\n",
    "    print(insert_statement)\n",
    "    run_statement = engine.execute(insert_statement)\n",
    "    for row in run_statement.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6be9f4-39c0-4095-9de9-a3be6682a238",
   "metadata": {},
   "source": [
    "Query data and Iceberg snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c6e46-3db0-4d70-827a-7e4132ca8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_query)\n",
    "dataset = engine.execute(dataset_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30713642-2a35-4a3f-bd1e-c9af57beca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snapshot_query)\n",
    "dataset = engine.execute(snapshot_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edfb329-fb1a-40b3-a2c2-161b6ff76f0f",
   "metadata": {},
   "source": [
    "Query only the first data set (Iceberg time machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8789c-45b4-4d9d-b5b5-0a4b38dfddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_dataset_query = ('SELECT * FROM osc_datacommons_iceberg_dev.{sname}.\\\"{tname}@6968266386201395358\\\"').format(sname=schemaname,tname=tablename)\n",
    "print(past_dataset_query)\n",
    "dataset = engine.execute(past_dataset_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91817f08-9b03-4c38-8c63-34ab12e8c26b",
   "metadata": {},
   "source": [
    "Rollback the second data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f352a-949a-42af-952b-492ff301fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_request = ('CALL osc_datacommons_iceberg_dev.system.rollback_to_snapshot(\\'{sname}\\', \\'{tname}\\', 6968266386201395358)').format(sname=schemaname,tname=tablename)\n",
    "print(rollback_request)\n",
    "dataset = engine.execute(rollback_request)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037ebb3-e5bd-4bb4-9f0d-19f543c30778",
   "metadata": {},
   "source": [
    "Query the full table again, the second data set has been rolled back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b0f52-dfce-4db8-9825-1d7643906d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_query)\n",
    "dataset = engine.execute(dataset_query)\n",
    "for row in dataset.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3da6ac-66fc-4987-81a7-dd65fd58e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
