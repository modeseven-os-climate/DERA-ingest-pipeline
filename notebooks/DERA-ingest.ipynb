{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abf0869-f139-411a-9b34-51945c12cade",
   "metadata": {},
   "source": [
    "# Ingest SEC DERA data into Trino pipeline\n",
    "\n",
    "Copyright (C) 2021 OS-Climate\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "Contributed by Michael Tiemann (Github: MichaelTiemannOSC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cbf87f-0bd3-41e1-acb8-c2508110c510",
   "metadata": {},
   "source": [
    "Run these in a notebook cell if you need to install onto your nb env\n",
    "\n",
    "```python\n",
    "# 'capture' magic prevents long outputs from spamming your notebook\n",
    "%%capture pipoutput\n",
    "\n",
    "# For loading predefined environment variables from files\n",
    "# Typically used to load sensitive access credentials\n",
    "%pip install python-dotenv\n",
    "\n",
    "# Standard python package for interacting with S3 buckets\n",
    "%pip install boto3\n",
    "\n",
    "# Interacting with Trino and using Trino with sqlalchemy\n",
    "%pip install trino sqlalchemy sqlalchemy-trino\n",
    "\n",
    "# Pandas and parquet file i/o\n",
    "%pip install pandas pyarrow fastparquet\n",
    "\n",
    "# OS-Climate utilities to make data ingest easier\n",
    "%pip install osc-ingest-tools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789567ff-268c-45e8-8f6f-e768ba62f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "from osc_ingest_trino import *\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7692120-2f4f-48be-9847-0f78a3359bc1",
   "metadata": {},
   "source": [
    "Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba14b4-0746-4ce6-9c0f-ff680221bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fa84b-d4c0-4dd6-99da-2cab1641ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_source = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_LANDING_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_LANDING_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_LANDING_SECRET_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3310c-218e-47b1-b12b-8d2c4fb3fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_trino = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ[\"S3_DEV_ENDPOINT\"],\n",
    "    aws_access_key_id=os.environ[\"S3_DEV_ACCESS_KEY\"],\n",
    "    aws_secret_access_key=os.environ[\"S3_DEV_SECRET_KEY\"],\n",
    ")\n",
    "bucket = s3_trino.Bucket(os.environ[\"S3_DEV_BUCKET\"])\n",
    "bucket.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efe080-b4eb-4713-8fd0-7f1d2e1fd966",
   "metadata": {},
   "source": [
    "Open a Trino connection using JWT for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0dce7-1762-4605-8617-f2bf6d649f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'sec_dera'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b5e63-8d67-4314-844c-ae42266070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trino\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD']),\n",
    "    'http_scheme': 'https'\n",
    "}\n",
    "engine = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(engine))\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96687d-74a7-46d8-9944-b63fddf11bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available schemas to ensure trino connection is set correctly\n",
    "schema_read = engine.execute(f'show schemas in {ingest_catalog}')\n",
    "for row in schema_read.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d59fd-f47a-4244-9b4a-3cd6d2d1f164",
   "metadata": {},
   "source": [
    "Enter the Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c5cf5-b15e-4ce0-ad90-e14661950f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c393385-3474-45bd-b41a-c5b4c522ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import osc_ingest_trino as osc\n",
    "\n",
    "_p2smap = {\n",
    "    'string': 'varchar',\n",
    "    'float32': 'real',\n",
    "    'Float32': 'real',\n",
    "    'float64': 'double',\n",
    "    'Float64': 'double',\n",
    "    'int32': 'integer',\n",
    "    'Int32': 'integer',\n",
    "    'int64': 'bigint',\n",
    "    'Int64': 'bigint',\n",
    "    'bool': 'boolean',\n",
    "    'category': 'varchar',\n",
    "    'datetime64[ns, UTC]': 'timestamp',\n",
    "}\n",
    "\n",
    "def pandas_type_to_sql(pt):\n",
    "    st = _p2smap.get(pt)\n",
    "    if st is not None:\n",
    "        return st\n",
    "    raise ValueError(\"unexpected pandas column type '{pt}'\".format(pt=pt))\n",
    "\n",
    "# add ability to specify optional dict for specific fields?\n",
    "# if column name is present, use specified value?\n",
    "def create_table_schema_pairs(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"df must be a pandas DataFrame\")\n",
    "    ptypes = [str(e) for e in df.dtypes.to_list()]\n",
    "    stypes = [pandas_type_to_sql(e) for e in ptypes]\n",
    "    pz = list(zip(df.columns.to_list(), stypes))\n",
    "    return \",\\n\".join([\"    {n} {t}\".format(n=e[0],t=e[1]) for e in pz])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9374b-114d-42e8-8eaa-14f67426b141",
   "metadata": {},
   "source": [
    "Prepare GLEIF matching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fae7f-ac39-4b37-9c82-4971c1daf649",
   "metadata": {},
   "outputs": [],
   "source": [
    "gleif_file = s3_source.Object(os.environ['S3_LANDING_BUCKET'],'mtiemann-GLEIF/DERA-matches.csv')\n",
    "gleif_file.download_file(f'/tmp/dera-gleif.csv')\n",
    "gleif_df = pd.read_csv(f'/tmp/dera-gleif.csv', header=0, sep=',', dtype=str, engine='c')\n",
    "gleif_dict = dict(zip(gleif_df.name, gleif_df.LEI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292b412-e27d-4ccf-a65f-0f00b47affe4",
   "metadata": {},
   "source": [
    "Drop previous tables and schema to start with a fresh slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f74df3-3715-4219-8303-48af7f78c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ingest_table in [ 'sub', 'num', 'tag', 'ticker' ]:\n",
    "    sql = f\"\"\"\n",
    "drop table if exists {ingest_catalog}.{ingest_schema}.{ingest_table}\n",
    "\"\"\"\n",
    "    print(sql)\n",
    "    qres = engine.execute(sql)\n",
    "    print(qres.fetchall())\n",
    "\n",
    "sql = f\"\"\"\n",
    "drop schema if exists {ingest_catalog}.{ingest_schema}\n",
    "\"\"\"\n",
    "print(sql)\n",
    "qres = engine.execute(sql)\n",
    "print(qres.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bdb125-1769-40f8-ace7-6daa29456c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure schema exists, or table creation below will fail in weird ways\n",
    "sql = f\"\"\"\n",
    "create schema {ingest_catalog}.{ingest_schema}\n",
    "\"\"\"\n",
    "print(sql)\n",
    "qres = engine.execute(sql)\n",
    "print(qres.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b20942-417b-40c7-a6b0-3bda008b1d98",
   "metadata": {},
   "source": [
    "Load `ticker` file (updated sporadically from https://www.sec.gov/include/ticker.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5495730-2363-42af-b146-7eca5cdb201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_file = s3_source.Object(os.environ['S3_LANDING_BUCKET'],'SEC-DERA/ticker.txt')\n",
    "ticker_file.download_file(f'/tmp/dera-ticker.txt')\n",
    "ticker_df = pd.read_csv(f'/tmp/dera-ticker.txt', names=['ticker', 'cik'], header=None, sep='\\t', dtype={'ticker':'string','cik':'int64'}, engine='c')\n",
    "ticker_dict = dict(zip(ticker_df.cik, ticker_df.ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f886392-62d5-4f94-abc7-82a5f0d9e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = io.BytesIO()\n",
    "ticker_df.to_parquet(path=buf)\n",
    "buf.seek(0)\n",
    "bucket.upload_fileobj(Fileobj=buf,\n",
    "                      Key=f'trino/{ingest_schema}/ticker/data.parquet')\n",
    "\n",
    "sql = f\"\"\"\n",
    "drop table if exists {ingest_catalog}.{ingest_schema}.ticker;\n",
    "create table {ingest_catalog}.{ingest_schema}.ticker(\n",
    "    name varchar,\n",
    "    cik bigint\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://{bucket.name}/trino/{ingest_schema}/ticker/'\n",
    ");\n",
    "select count (*) from {ingest_catalog}.{ingest_schema}.ticker\n",
    "\"\"\"\n",
    "for sql_stmt in sql.split(';'):\n",
    "    print(sql_stmt)\n",
    "    qres = engine.execute(sql_stmt)\n",
    "    print(qres.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902df315-a8f2-43e3-9d1c-f1bdddeae1a9",
   "metadata": {},
   "source": [
    "Load the SUB, NUM, and TAG tables into Trino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408dc1fb-9249-465d-98b1-5280c4e3ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "\n",
    "# Add a unique identifier to the data set\n",
    "uid = str(uuid.uuid4())\n",
    "\n",
    "dera_regex = re.compile(r' ?/.*$')\n",
    "\n",
    "quarters = ['2020q1', '2020q2', '2020q3', '2020q4', '2021q1', '2021q2', '2021q3']\n",
    "\n",
    "def ingest_dera_table(qtr, tbl):    \n",
    "    src_file = s3_source.Object(os.environ['S3_LANDING_BUCKET'],f'SEC-DERA/{qtr}/{tbl}.txt')\n",
    "    timestamp = src_file.last_modified.isoformat()\n",
    "    src_file.download_file(f'/tmp/dera-{tbl}-{timestamp}.csv')\n",
    "    df = pd.read_csv(f'/tmp/dera-{tbl}-{timestamp}.csv', header=0, sep='\\t', dtype='string', keep_default_na=False, nrows = None, engine='c')\n",
    "    \n",
    "    df['uuid'] = uid\n",
    "    df['quarter'] = qtr\n",
    "    df = df.convert_dtypes (infer_objects=False, convert_string=True, convert_integer=False, convert_boolean=False, convert_floating=False)\n",
    "    # Print the output\n",
    "    # print(df.dtypes)\n",
    "    \n",
    "    if tbl=='sub':\n",
    "        df.name = df.name.map(lambda x: re.sub(dera_regex, '', x))\n",
    "        df.name = df.name.astype('string')\n",
    "        df['LEI'] = df.name.map(gleif_dict)\n",
    "        df.LEI = df.LEI.astype('string')\n",
    "        df.cik = df.cik.astype('int32')\n",
    "        df.loc[df.sic=='', 'sic'] = pd.NA\n",
    "        df.sic = df.sic.astype('Int32')\n",
    "        df.loc[df.ein=='', 'ein'] = pd.NA\n",
    "        df.ein = df.ein.astype('Int64')\n",
    "        df.wksi = df.wksi.astype('bool')\n",
    "        # df.wksi = df.wksi.astype('int32')\n",
    "        df.period = pd.to_datetime(df.period, format='%Y%m%d', utc=True, errors='coerce')\n",
    "        df.fy = pd.to_datetime(df.fy, format='%Y', utc=True, errors='coerce')\n",
    "        df.filed = pd.to_datetime(df.filed, format='%Y%m%d', utc=True)\n",
    "        df.accepted = pd.to_datetime(df.accepted, format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "        df.prevrpt = df.prevrpt.astype('bool')\n",
    "        df.detail = df.detail.astype('bool')\n",
    "        # df.prevrpt = df.prevrpt.astype('int32')\n",
    "        # df.detail = df.detail.astype('int32')\n",
    "        df.nciks = df.nciks.astype('int32')\n",
    "        \n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[0:3] + [cols[-1]] + cols[3:-1]\n",
    "        df = df[cols]\n",
    "    elif tbl=='num':\n",
    "        # documentation wrongly lists coreg as NUMERIC length 256.  It is ALPHANUMERIC.\n",
    "        df.ddate = pd.to_datetime(df.ddate, format='%Y%m%d', utc=True)\n",
    "        df.qtrs = df.qtrs.astype('int32')\n",
    "        df.loc[df.value=='', 'value'] = pd.NA\n",
    "        df.value = df.value.astype('Float64')\n",
    "    elif tbl=='tag':\n",
    "        df.custom = df.custom.astype('bool')\n",
    "        df.abstract = df.abstract.astype('bool')\n",
    "    print(df.dtypes)\n",
    "    display(df.head())\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    df.to_parquet(path=buf)\n",
    "    buf.seek(0)\n",
    "    bucket.upload_fileobj(Fileobj=buf,\n",
    "                          Key=f'trino/{ingest_schema}/{tbl}/{qtr}.parquet')\n",
    "\n",
    "    # Once we have all our parquet files in place, load up the table\n",
    "    if qtr==quarters[-1]:\n",
    "        table_check = engine.execute(f'drop table if exists {ingest_catalog}.{ingest_schema}.{tbl}')\n",
    "        for row in table_check.fetchall():\n",
    "            print(row)\n",
    "\n",
    "        columnschema = create_table_schema_pairs(df)\n",
    "        tabledef = f\"\"\"\n",
    "create table if not exists {ingest_catalog}.{ingest_schema}.{tbl} (\n",
    "{columnschema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://{bucket.name}/trino/{ingest_schema}/{tbl}/'\n",
    ")\n",
    "\"\"\"\n",
    "        print(tabledef)\n",
    "\n",
    "        table_create = engine.execute(tabledef)\n",
    "        for row in table_create.fetchall():\n",
    "            print(row)\n",
    "\n",
    "        dataset_query = (f'SELECT * FROM {ingest_catalog}.{ingest_schema}.{tbl} limit 10')\n",
    "        print(dataset_query)\n",
    "        dataset = engine.execute(dataset_query)\n",
    "        for row in dataset.fetchall():\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72450a-11ed-403a-a43a-496571347529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for qtr in quarters:\n",
    "    for ingest_table in [ 'sub', 'num', 'tag' ]:\n",
    "        print(f'Ingesting table {ingest_table}; quarter = {qtr}; timestamp = {str(datetime.now())}')\n",
    "        \n",
    "        ingest_dera_table(qtr, ingest_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375a547-4e34-484b-8ff4-b40416be315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrow metadata code from DERA-iceberg if/when we need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285fe0e-e7ce-4c5b-8f2d-d6496e766ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablenames = ['sub', 'num', 'tag', 'ticker']\n",
    "l = []\n",
    "for tbl in tablenames:\n",
    "    qres = engine.execute(f'select count (*) from {ingest_catalog}.{ingest_schema}.{tbl}')\n",
    "    l.append(qres.fetchall()[0])\n",
    "print(list(zip(tablenames, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f472a30-40e4-4632-918b-11457e2ac45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
